%!TEX root = ../report.tex
\chapter{Improving Build Times}
The multi-project groups want the build times on Jenkins to be faster. When multiple changes are pushed to the master branch within a short space of time, the triggered build jobs will congest the build queue. This means that even though the build itself may take only a few minutes, the time it takes from push to finished build may be much longer and exceed the 10 minutes advocated by \textcite{beck2004}.

\begin{chapterorganization}
  \item in \sectionref{sec:measuring_build_times} we measure the time of building the Launcher app;
  \item in \sectionref{sec:dependency_management} we present an alternative solution to the current Git submodule dependency system;
  \item in \sectionref{sec:dependency_repository} we choose a dependency repository for storing binaries;
  \item in \sectionref{sec:dependency_workflow} we define the workflow for the multi-project developers when working with the new dependency system;
  \item in \sectionref{sec:conf_project_to_publish} we configure the Giraf projects to use the new dependency system;
  \item in \sectionref{sec:automating_vm} we describe how versions of binaries are automatically managed;
  \item in \sectionref{sec:emulator_bug} we describe a serious bug in the Android Emulator plugin for Jenkins and present a solution;
  \item in \sectionref{sec:faster_build_evaluation} we evaluate the build times after implementing binary dependencies;
  \item in \sectionref{sec:non-emulator_testing} we discuss the opportunity to improve build times further by implementing non-emulator testing.
\end{chapterorganization}

\section{Measuring Build Times}\label{sec:measuring_build_times}
We measure the build time of the different parts of the Launcher project in order to identify which parts of the build process to make faster. The Launcher project is the main application which depends on many other subprojects (henceforth a ``dependency''). These dependencies are managed as Git submodules \parencite{git-submodules-doc}, which basically clones the contents of a repository (the dependency) at a specific revision into another repository (the dependent project). The build timings are measured on the Jenkins server and shown in \figureref{fig:launcher_build_times_1} (slow emulator). This shows the build timings of the Launcher application and the dependencies \emph{Oasis-lib}, \emph{Giraf-Component}, \emph{Local-db}, \emph{Barcode-scanner}, and \emph{Metadata}, as well as the start up time of the emulator. Notice that the \emph{Metadata} dependency takes so little time that it cannot be seen. As can be seen, the emulator, the \emph{Giraf-component}, and the \emph{Oasis-lib} projects have the most significant influence on build times. These three parts use about \SI{90}{\percent} of the total build time. The actual Launcher application itself takes only very little part of the total build time.

To understand which parts of the dependencies that take time, we measure the individual build steps (tasks) performed during a build. These can be seen in \appendixref{app:build_times}. The reason that the \emph{Oasis-lib} dependency takes a long time to build is that it contains a great number of tests which run on the emulator. These tests are run every time a project depending on \emph{Oasis-lib} builds --- even though the library itself has not been updated. The most significant task when building the \emph{Giraf-Component} library is the test task as well. However, the \emph{Giraf-Component} library only contains one simple test, so we do not expect the actual test execution time to use much of this time. Instead, we expect it to be caused by the order in which projects are tested. When preparing the tests, the tests from all projects are combined into a single Android application package (APK-file). The first test task run is responsible for installing this application on the emulator, while the subsequent test tasks can skip this step. Because the \emph{Giraf-components} project is the first in the sequence of libraries to be tested, this task also installs the tests on the emulator which is likely to take some time.

\begin{figure}
\centering
\tikzsetnextfilename{timings_beforeemulatorupdate}
\begin{tikzpicture}[]
  \begin{axis}[
    xbar stacked,
    scale only axis,
    width=\textwidth-\widthof{Slow emulator}-0.1cm,
    axis y line*= none, axis x line*= bottom,
    %xmajorgrids = true,
    ytick = data,
    yticklabels = {Slow emulator, Fast emulator},
    yticklabel style={inner sep=0pt, align=right, xshift=-0.1cm},
    tick align = outside,
    %xtick pos = left,
    bar width=6mm,
    y=8mm,
    enlarge y limits={abs=0.625},
    %nodes near coords,
    legend style={
      at={(0.5,-0.55)},
      legend columns=4,
      anchor=north,
      yshift=0ex,
      xshift=0ex,
      draw=none,
      legend cell align=left
    },
    area legend,
    xlabel = {Time (seconds)},
    xmin = 0
  ]
    \addplot[colorCshade, fill=colorC] coordinates
    {(115.000,0) (18.000,1)};
    \addlegendentry{Emulator}
    \addplot[colorGshade, fill=colorG] coordinates
    {(0.28,0) (0.28,1)};
    \addlegendentry{Metadata}
    \addplot[colorFshade, fill=colorF] coordinates
    {(7.711,0) (7.711,1)};
    \addlegendentry{Barcode-scanner}
    \addplot[colorEshade, fill=colorE] coordinates
    {(8.393,0) (8.393,1)};
    \addlegendentry{Launcher}
    \addplot[colorDshade, fill=colorD] coordinates
    {(17.315,0) (17.315,1)};
    \addlegendentry{Local-db}
    \addplot[colorBshade, fill=colorB] coordinates
    {(105.782,0) (105.782,1)};
    \addlegendentry{Giraf-component}
    \addplot[colorAshade, fill=colorA] coordinates
    {(159.739,0) (159.739,1)};
    \addlegendentry{Oasis-lib}
  \end{axis}
\end{tikzpicture}
\caption{Timings during build of the Launcher project before and after updating emulator plugin}\label{fig:launcher_build_times_1}
\end{figure}
\kimnote{The Seconds label is not visiable. Os: Det st√•r efter ref til figur hvorfor}

As a preparation step, we first update the Android Emulator Jenkins plugin \parencite{jenkins-emulator-plugin} to a new version with improved emulator stability. We do this to ensure that we do not work on improving parts which are already improved in the most recent version of the plugin. After updating, we measure the build times again. As shown in \figureref{fig:launcher_build_times_1} (fast emulator), the emulator startup time is significantly decreased. Because of this, the emulator startup time is no longer the primary concern, and we focus on decreasing the dependency build times.

One obvious way of decreasing overall build times is to use faster hardware on the server. However, because the multi-project has no financial income, buying new hardware is generally the last resort. In addition, it is difficult to estimate exactly how much of a decrease this will give in practice. Another option is to not test dependencies when dependent projects are build, but only when changes happen in the actual dependency project. While this will decrease the overall build times, each dependency is still built every time a dependent project is built, which limits the amount by which we can decrease the total build times. Not testing each build of dependencies, however, is not favorable. Because of this, we look at improving the build times in a different way, specifically by using pre-compiled libraries.

\section{Dependency Management}\label{sec:dependency_management}
Instead of building and testing dependencies each time a dependent project is built, we look at referencing pre-compiled and pre-tested library files. We are inspired by the way \mono{.jar}-files are typically used as libraries for Java projects. This way of managing libraries has a number of advantages compared to the current setup:
\begin{description}
  \item [Pre-Compiled and Pre-Tested] Libraries are binary pre-compiled and pre-tested files. This means that dependent projects do not have to build and test all dependencies, which decreases the build time significantly.
  \item[Quality Control] Libraries are built and released only if the tests pass, so there will never be dependencies which cannot compile or do not work\footnote{Of course, there may be bugs even if all tests pass, but good test cases decrease the risk}.
  \item[Integrity] All libraries are built on the same machine and build environment, which means that no machine-specific configurations will influence the released libraries \parencite{humble2010, huttermann2014}.
  \item[Cleaner Structure] Nested dependencies (dependency A depends on dependency B which depends on dependency C) is well defined and nicely handled. The individual libraries do not include their dependencies, so it is always the dependent library that has to include all dependencies. Currently, the same dependency may be included multiple times in the same project.
\end{description}
The Android counterpart of Java \mono{.jar}-files is \mono{.aar}-files. These files are similar to \mono{.jar}-files, except that they can contain Android-specific dependencies such as icon resources as well \parencite{android-aar}.

With this solution, it is clear that we no longer want to use submodules for managing dependencies. Coincidentally, the Git-responsible group in the multi-project work on a user story which states \us{Remove Git submodules}. The reason for this user story is that the developers generally find the submodules difficult to work with. Because this overlap with our solution to making build times faster, we decide to solve this in collaboration.

An important requirement for the solution, besides removing Git submodules and improving build times, is that every build should be reproducible. This means that we must be able to reproduce any previously released version. This is a very important part of continuous integration as it makes it possible to reproduce bugs from previous versions \parencite{fowlerReproducibleBuild,humble2010}. In the current way of managing dependencies, this requirement is fulfilled.

\subsection{Agreement Upon Submodule Replacement Strategy}
The Git-responsible group initially propose to remove submodules by merging all repositories into one, each project having its own directory located in the root directory of the repository, as shown in \figureref{fig:single_repo_structure}. Dependencies are then handled by referring to the relative path of the dependency. For example, if \mono{ProjectA} depends on \mono{ProjectB}, \mono{ProjectA} will contain a reference to \mono{../ProjectB}. This solution makes all releases reproducible, which is one of the requirements to the solution. The repository can simply be checked out to a specific commit corresponding to a specific release.
\begin{figure}
  \dirtree{%
.1 /.
.2 ProjectA.
.3 \ldots.
.2 ProjectB.
.3 \ldots.
.2 ProjectC.
.3 \ldots.
.2 ProjectD.
.3 \ldots.
}
\caption{Single repository file structure} \label{fig:single_repo_structure}
\end{figure}
A problem with this, however, is that the structure does not use pre-compiled libraries and as such it does not decrease build times as much as we want. Each dependency is built every time the dependent project is built.

An additional problem is that all projects are forced to use the most recent versions of its dependencies. As soon as a dependency is updated, it is automatically applied in all dependent projects. If the interface to a library changes without keeping backward compatibility, all dependent projects will stop working.

Instead, we need a structure which allows projects to reference their dependencies as pre-built libraries while being able to reproduce any build in history. For inspiration, we look at how dependency management is done in the five most starred Android projects on Github\footnote{As of April \nth{15}, these are \emph{ioshed}, \emph{ViewPagerIndicator}, \emph{retrofit}, \emph{EventBus}, and \emph{PhotoView}.}. In all of these projects, dependencies are handled by Gradle and Maven. Maven is a build tool similar to Gradle, but its dependencies management mechanisms are supported in many build tools, including Gradle. Dependencies are declared in the build configuration file, for example in a Gradle file, each of which uniquely identified with a group (package), name, and version number. \listingref{lst:dependency_declaration} shows how a dependency (the \emph{gson} library) is declared in a Gradle file. When the project is built, the build system automatically searches for the dependencies on the declared repositories and downloads them. Because the version code (\mono{2.0} in this case) is used to identify dependencies, and the build file is under version control, it is possible reproduce builds.

\begin{gradlecode}[caption={Dependency declaration in Gradle},label={lst:dependency_declaration}]
repositories {
  mavenCentral()
}
dependencies {
  compile 'com.google.code.gson:gson:2.0'
}
\end{gradlecode}

\section{Dependency Repository}\label{sec:dependency_repository}
By hosting our own internal Maven artifact repository for our libraries, we are able to declare the dependencies in the build-file and at the same time remove Git submodules and make builds happen faster. This means that we use a separate repositories for source code and binary files. The main reason for this is that Git does not handle binary files well. It keeps every version of binary files \parencite{gitwebsite_attributes}, which will use much space over time. In an artifact repository, on the other hand, only release versions of libraries and a configurable number of development (pre-release) versions are saved.

Different pieces of software for managing artifact repositories exist, which we will present in this section. We restrict ourselves to looking at free repository systems supported by Gradle \parencite{gradle-dependencies-doc}: \emph{Apache Archiva} \parencite{archiva-website}, \emph{Sonatype Nexus} \parencite{nexus-website}, and \emph{Artifactory} \parencite{artifactory-website}. Overall, the only requirements for an artifact repository management system are:
\begin{description}
  \item[Repository Browser] It should be possible to browse the artifacts in the repositories, so that the developers can identify the most recent versions of the libraries.
  \item[Role Management] Every developer should be able to browse the repository, but only specific people should be able to configure the repositories.
\end{description}
Each of the three repository systems comply with these requirements. They can all be browsed and configured through a web server. As such, it does not really matter which system we choose. We choose to use Artifactory because it has a plugin for Jenkins which may be useful for future projects. We install the software on our server and do the actual submodule replacement in collaboration with the Git responsible group.

\section{Dependency Workflow}\label{sec:dependency_workflow}
Because of the new way of managing dependencies, all developers have to change their workflows. To make the transition run smooth, we define a workflow for the new structure, which defines the following tasks:
\begin{description}
  \item[Release Management and Versioning] During development, libraries should be released as work-in-progress artifacts. When they are stable, new versions should be released.
  \item[Declaring Dependencies] It should be clear for the developers how to declare dependencies and their versions.
  \item[Local Development] Developers should be able to test changes to libraries in dependent projects without committing them to the master branch.
\end{description}

We demonstrate this workflow to the multi-project groups at the sprint end, so that they know how to work with the new dependency system. We also write a guide which they can use for future reference. The guide is written in Danish and can be seen in \appendixref{app:dependency_workflow_guide}.

\subsection{Release Management and Versioning}\label{subsec:release-management}
With the introduction of artifacts, we now distinguish release versions from pre-release versions. In addition, a release can be a \emph{major}, \emph{minor}, or \emph{patch} release. The developers need some guidelines to know when to release the different kind of releases. Rather than inventing our own convention, we rely on the Semantic Versioning 2.0.0 specification \parencite{semver2015}, which has been adopted in several Apache projects \parencite{apacheapr,apacheisis,apacheaccumulo}. Because the versioning is clearly specified, we expect to avoid potential problems caused by libraries breaking backward compatibility. In summary, the Semantic Versioning 2.0.0 specification states that the version name is of the form \mono{major.minor.patch}, each of which being a non-negative integer. For example, version \mono{2.5.1} has major version 2, minor version 5, and patch version 1. The individual numbers are increased as new versions are released. To summarize the Semantic Versioning 2.0.0 specification, the numbers are increased according to the following:
\begin{description}
  \item[Major] When changes without backward compatibility are introduced, it should be released as a new major version. The minor and patch numbers are reset to 0.
  \item[Minor] Minor releases are used when new functionality is added with backward compatibility. The major version is unchanged and the patch version is reset to 0.
  \item[Patch] A patch is for introducing changes without new functionality (typically bug fixes). The major and minor versions are left unchanged.
\end{description}

During development, pre-release versions can be denoted by the version code followed by a hyphen and an identifier (e.g.\ \mono{2.5.1-ALPHA} or \mono{2.5.1-SNAPSHOT}). Due to the specifics of Maven dependencies, we require this identifier to always be \mono{SNAPSHOT}. This enables Maven to handle pre-releases differently than release versions.

\subsection{Declaring Dependencies}
The new pre-built dependencies are declared almost the same way as previously. Instead of referring a path to a local directory containing the dependency, the reference is declared as a Maven dependency (as previously described). To accommodate this, we release the current version of each library as version 1.0.0 and make all dependent projects reference these. \listingref{lst:dependency_declaration_giraf} shows an example of how the dependencies are declared for a Giraf-project, including the declaration of the repository containing the dependencies.

\begin{gradlecode}[caption={Dependency declaration for a Giraf project},label={lst:dependency_declaration_giraf}]
repositories {
    maven {
        url 'http://cs-cust06-int.cs.aau.dk/artifactory/libraries'
    }
    mavenLocal()
}

dependencies {
    compile(group: 'dk.aau.cs.giraf', name: 'girafComponent', version: '1.3.0-SNAPSHOT', ext: 'aar')
    compile(group: 'dk.aau.cs.giraf', name: 'oasisLib', version: '1.1.2', ext: 'aar')
}
\end{gradlecode}

\subsection{Local Development}
Developers must be able to test their changes in the dependent projects locally without committing their changes, as part of continuous integration \parencite{fowlerCI}. Our solution is to publish the dependency on a local Maven repository on every development machine. To test the dependency in another project, the dependent project points to the local repository rather than that on the common repository. Conveniently, the Maven plugin for Gradle has support for publishing and referring to local repositories. The build task \mono{publishToMavenLocal} publishes an artifact to the local repository.

\figureref{fig:dependency_overview} shows an overview of the dependency management workflow, from local development to releasing artifacts on Artifactory.

\begin{figure}%
  \centering
  \tikzsetnextfilename{version_management}
  \begin{tikzpicture}
    \path (0,0)
      node[cloud, cloud puffs=14.2, cloud ignores aspect, minimum width=2.8cm, minimum height=1.3cm, align=center, draw, anchor=west] (git-cloud) at (0, 0) {Git repository}
      -- (\textwidth/2,0) node[cloud, cloud puffs=13.6, cloud ignores aspect, minimum width=2.3cm, minimum height=1.3cm, align=center, draw] (jenkins-cloud) {Jenkins}
      -- (\textwidth-1mm,0) node[cloud, cloud puffs=14.8, cloud ignores aspect, minimum width=2.6cm, minimum height=1.3cm, align=center, draw, anchor=east] (art-cloud) {Artifactory};

    \draw[->, dashed] (git-cloud) -- node[anchor=south] {Trigger build} (jenkins-cloud);
    \draw[->, dashed] (jenkins-cloud) -- node[anchor=south] {Release artifact} (art-cloud);

    \node[draw, minimum height=1cm, minimum width=3cm, below=1cm of jenkins-cloud] (devmachine) {Dev machine};
    \node[draw, minimum height=1cm, minimum width=3cm, below=1cm of devmachine] (localrepo) {Local repository};

    \draw[->] ([xshift=-0.8cm]localrepo.north) -- node[anchor=east] {Gradle \mono{GetDeps}} ([xshift=-0.8cm]devmachine.south);
    \draw[->] ([xshift=0.8cm]devmachine.south) -- node[anchor=west] {Gradle \mono{PublishToMavenLocal}} ([xshift=0.8cm]localrepo.north);

    \draw[->] (devmachine) -- node[anchor=east, yshift=-5pt] {Git push} (git-cloud);
    \draw[->] (art-cloud) -- node[anchor=west, yshift=-5pt] {Gradle \mono{GetDeps}} (devmachine);

  \end{tikzpicture}
  \caption[Overview of dependency management workflow]{Overview of dependency management workflow. A cloud represents a server application. Filled arrows represent actions initiated by the developer, and dashed lines represent actions initiated by a server applications. The direction of arrows indicate in which direction data (source code or binary data) is transmitted.}%
  \label{fig:dependency_overview}%
\end{figure}

\section{Configuring the Projects to Publish}\label{sec:conf_project_to_publish}
Each library project has to be configured to publish, locally and to Artifactory. This configuration is done in the build files. Instead of having to repeat the same information in the build file for every library project, we make a Gradle plugin which defines all properties needed for publishing, called the \mono{giraf-lib-gradle-plugin}. The plugin contains the URL to the snapshot and release repositories, the path to a credentials file (to Artifactory), and configurations for local publishing. It also declares a rename task, which renames the output file, such that Jenkins knows its name when it is to upload it. At last, it makes the \mono{publishToMavenLocal} task dependent on the \mono{build} task, as it would be a hassle to manually make sure to build first. With this plugin we only have to apply it in the build files to make them publish to Artifactory.\todo{Tilf√∏j kode til appendiks?}

Because the credentals file is stored on the build server, it is also not possible for the developers to publish libraries themselves; each build must pass on Jenkins before it is released.

\section{Automating Dependency Management}\label{sec:automating_vm}
With the dependency workflow defined, we integrate it with continuous integration. As earlier mentioned, we want to automate as much as possible to ease the work of the developers. For dependency management, Gradle already does a lot for us: It automatically locates and downloads declared dependencies and creates tasks for publishing new ones to the artifact repository.

In addition to this, we automate release versioning to some degree. Developers need not to declare the version of a library in its build file --- instead, they simply include the keywords \mono{@patch}, \mono{@minor}, or \mono{@major} in the commit message to release a patch, minor, or major version, respectively. This automatically takes care of increasing and resetting version numbers. For example, if the current version is \mono{1.2.3}, a \mono{@minor} keyword will release a new artifact with version \mono{1.3.0}. If no keyword is given, the release is assumed to be a pre-release, which causes the version name to be the \emph{next} patch release number with a \mono{-SNAPSHOT} postfix (e.g.\ \mono{1.2.4-SNAPSHOT} if the most recent release is \mono{1.2.3}). If multiple commits are pushed at the same time, we trigger only one pre-release build per release. For example, if it contains four commits with messages \mono{test1}, \mono{test2}, \mono{@patch}, \mono{test3}, respectively, two pre-releases (one before and one after the patch) and one patch are build. Similarly, if a push contains several commits without any release keyword, only one pre-release will be built. \figureref{fig:git_library_versions} illustrates this behavior.
\begin{figure}
  \centering
  \tikzsetnextfilename{git_library_versions}
  \begin{tikzpicture}[node distance=.4cm,
  simple/.style={draw, circle, minimum size=0.5cm}]

  %Commit nodes
  \node[simple] (master-1) at (0,0) {A};
  \node[simple, draw opacity=0, fill opacity=0, right=of master-1, xshift=0.3cm] (dummy) {A};
  \node[simple, below=of dummy] (local-1) {B};
  \node[simple, below=of local-1] (local-2) {C};
  \node[simple, below=of local-2] (local-3) {D};
  \node[simple, below=of local-3] (local-4) {E};
  \node[simple, draw opacity=0, fill opacity=0, below=of local-4] (dummy2) {A};
  \node[simple, left=of dummy2, xshift=-0.3cm] (master-2) {F};

  %Versions
  \node[right=of local-3] (major-version) {\mono{1.2.4}};
  \node[right=of dummy] (init-version) {\mono{1.2.3}};
  \node[right=of local-2] (old-snap) {\mono{1.2.4-SNAPSHOT}};
  \node[right=of local-4] (new-snap) {\mono{1.2.5-SNAPSHOT}};

  %Patch node
  \node(patch-note) [right=of local-3, xshift=4cm] {\mono{@patch}};

  %Titles
  \node[above=of master-1, yshift=0cm] (master) {\phantom{g}Master\phantom{g}};
  \node[above=of dummy, yshift=0cm] (local) {\phantom{g}Local\phantom{g}};
  \node[simple, draw opacity=0, fill opacity=0, right=of dummy] (dummy3) {A};
  \node[right=of local, xshift=-0.55cm] (version) {\phantom{g}Version\phantom{g}};
  \node[right=of local, xshift=3.6cm] (commitmsg) {Keyword};

  \draw[->] (local-1) -- (master-1);
  \draw[->] (local-2) -- (local-1);
  \draw[->] (local-3) -- (local-2);
  \draw[->] (local-4) -- (local-3);
  \draw[->] (master-2) -- (local-4);
  \draw[->] (master-2) -- (master-1);

  \end{tikzpicture}
\caption[Behavior of version codes for libraries]{Behavior of version codes for libraries. The circles represents commits. The Master and Local columns indicates if the commits are local, or pushed to the master branch. the Version column indicates the version number given to the commit. The keyword column represents keyword in the commit message, if any are present. }\label{fig:git_library_versions}
\end{figure}
The Git hook previously described is extended with functionality to manage this. We implement this automation in collaboration with the Git-responsible group. As part of the implementation phase, we refactor by changing the programming language from Bash to Python, because of the greater level of abstraction provided by Python compared to Bash. Part of the code is shown in \listingref{lst:git_hook_trigger_build}. This function is called for each commit message contained in the push. It first identifies the library corresponding to the repository pushed to (lines \ref{githook:13}--\ref{githook:14}), and afterwards checks for keywords in the git message and formats the new version name (lines \ref{githook:18}--\ref{githook:33}). Jenkins is then triggered with a HTTP POST request containing the Jenkins job name, the version name of the release, and the commit id of the release commit as arguments. Finally, the library versions are updated in a global library object and the version name is printed to the user. The full code can be seen in \appendixref{sec:app_git_hook_post}. The most recent versions of the different libraries are stored in a file together with the names of their repositories and Jenkins jobs.

\begin{pythoncode}[caption=Part of the git hook responsible for setting library version names and triggering Jenkins,label=lst:git_hook_trigger_build]
def trigger_build(commit_msg, commit_id, libraries, repo_name, publish_snapshot=False):
    """
    Triggers a build on Jenkins.

    Parameters:
        commit_msg:       The contents of the commit message. Used for versioning.
        commit_id:        The id of the commit to build.
        libraries:        The known libraries and their versions.
        repo_name:        The name of the repository.
        publish_snapshot: If true, snapshots will be published.
    """
    version_name = ""
    for lib in libraries: (*@\label{githook:13}@*)
        if lib.name == repo_name and commit_msg != None: (*@\label{githook:14}@*)
            new_major = lib.major
            new_minor = lib.minor
            new_patch = lib.patch
            if "@major" in commit_msg.lower(): (*@\label{githook:18}@*)
                new_major = str(int(lib.major) + 1)
                new_minor = "0"
                new_patch = "1"
                version_name = "%s.0.0" % (new_major,)
            elif "@minor" in commit_msg.lower():
                new_minor = str(int(lib.minor) + 1)
                version_name = "%s.%s.0" % (lib.major, new_minor)
                new_patch = "1"
            elif "@patch" in commit_msg.lower():
                version_name = "%s.%s.%s" % (lib.major, lib.minor, lib.patch)
                new_patch = str(int(lib.patch) + 1)
            else:
                if not publish_snapshot:
                    return
                version_name = "%s.%s.%s-SNAPSHOT" % (lib.major, lib.minor, lib.patch) (*@\label{githook:33}@*)
            # Send request
            try:
                send_build_request(lib.jobname, version_name, commit_id)
                # Apply lib changes (request succeeded)
                lib.major = new_major
                lib.minor = new_minor
                lib.patch = new_patch
                print_version_name(version_name)
            except (ConnectionError, Timeout) as e:
                print "ERROR TRIGGERING BUILD"
                print e
            return
\end{pythoncode}

\section{Android Emulator Bug}\label{sec:emulator_bug}
When we started to work on improving build times, a new version of the Android Emulator Plugin (2.13) was released. This release contains a change in the way emulator startup is detected. It is necessary to detect when the Android emulator has started, so that APKs can be installed on it and tests can be run. Previously the plugin had checked whether the emulator has started up using \code{adb shell getprop dev.bootcomplete}. However, this property does not specify that the emulator has started fully, as it may still be in the boot animation when this property returns true. As such the check was switched to  \code{adb shell getprop init.svc.bootanim} which indicates that the emulator is no longer in the boot animation, and thus have started fully. However, since the emulator in the plugin has the \code{-no-boot-anim} flag, the emulator has no boot animation. This is to improve loading times, but it also means that the new check for the boot animation will return true immediately, as there is no boot animation. This results in the plugin specifying that the emulator is ready too early, which can lead to potential errors when working with the emulator.

At first this change did not affect us, since building times when building submodules were sufficiently long for the emulator to have started fully regardless. However, as we improve building times with binary dependencies, we start getting errors because of the not yet started emulator. We submit a bug report for the plugin\footnote{\url{https://issues.jenkins-ci.org/browse/JENKINS-27702}} and a pull request removing the \code{-no-boot-anim} flag for the compiler\footnote{\url{https://github.com/jenkinsci/android-emulator-plugin/pull/49}}. Removing the \code{-no-boot-anim} flag will result in slightly longer loading times for the emulator, but is necessary to detect that the emulator has started fully.

\section{Evaluation of Build Times with Binary Dependencies}\label{sec:faster_build_evaluation}
We measure the time of building the launcher after having implemented binary dependencies. To make a fair comparison, we run the launcher with the same Gradle tasks as previously measured (\code{check connectedCheck assembleRelease}), whereas in fact we now run every app with \code{clean check connectedCheck increaseVersionCode assembleRelease publishApkRelease}. The \code{increaseVersionCode} and \code{publishApkRelease} tasks make it possible to publish apps to Google Play. In addition, the \code{clean} task is run initially to ensure that a previous build does not affect the current build.

As mentioned in the previous section, we discovered a bug with the Android Emulator plugin on Jenkins after implementing binary dependencies that resulted in the very fast startups shown in \figureref{fig:launcher_build_times_1}. We therefore compare the build times with the emulator starting correctly (and therefore slowly).

\figureref{fig:launcher_build_times_2} shows three bars. \emph{Old slow} shows the build times before the new dependency system with the emulator working correctly. \emph{New few tasks} shows the build times with the build targets \code{check connectedCheck assembleRelease}. When running the same build tasks as before, there is an improvement in the build times of 43.6 \%, as the dependencies \emph{Local-db}, \emph{Giraf-component}, and \emph{Oasis-lib} are not built. \emph{Barcode-scanner} is still built, as it is not a library used for any other projects than the launcher. The build time for \emph{Launcher} has increased. This is because additional work has been done on the Launcher by other groups in parallel with us making the dependency changes.

The complete build time with the added Gradle tasks (\emph{New all tasks}) is, as expected, more than when running fewer targets. The time for the Barcode-scanner and Launcher has increased because they run additional tasks. On comparable configurations, we achieve a significant time reduction of 43.6 \% but some of these gains are eaten by the increased work added by the extra tasks and the resulting reduction of build time is just 13.7 \%.

\begin{figure}
\centering
\tikzsetnextfilename{launcher_timings}
\begin{tikzpicture}[]
  \begin{axis}[
    xbar stacked,
    scale only axis,
    width=\textwidth-\widthof{New few tasks}-0.1cm,
    axis y line*= none, axis x line*= bottom,
    %xmajorgrids = true,
    ytick = data,
    yticklabels = {Old slow, New few tasks, New all tasks},
    yticklabel style={inner sep=0pt, align=right, xshift=-0.1cm},
    tick align = outside,
    %xtick pos = left,
    bar width=6mm,
    y=8mm,
    enlarge y limits={abs=0.625},
    %nodes near coords,
    legend style={
      at={(0.5,-0.55)},
      legend columns=4,
      anchor=north,
      yshift=0ex,
      xshift=0ex,
      draw=none,
      legend cell align=left
    },
    area legend,
    xlabel = {Time (seconds)},
    xmin = 0
  ]
    \addplot[colorCshade, fill=colorC] coordinates
    {(115.000,0) (115.000,1) (115.000,2)};
    \addlegendentry{Emulator}
    \addplot[colorGshade, fill=colorG] coordinates
    {(0.28,0) (0.0,1) (0.0,2)};
    \addlegendentry{Metadata}
    \addplot[colorFshade, fill=colorF] coordinates
    {(7.711,0) (18.274,1) (36.135,2)};
    \addlegendentry{Barcode-scanner}
    \addplot[colorEshade, fill=colorE] coordinates
    {(8.393,0) (100.277,1) (206.314,2)};
    \addlegendentry{Launcher}
    \addplot[colorDshade, fill=colorD] coordinates
    {(17.315,0) (0.0,1) (0.0,2)};
    \addlegendentry{Local-db}
    \addplot[colorBshade, fill=colorB] coordinates
    {(105.782,0) (0.0,1) (0.0,2)};
    \addlegendentry{Giraf-component}
    \addplot[colorAshade, fill=colorA] coordinates
    {(159.739,0) (0.0,1) (0.0,2)};
    \addlegendentry{Oasis-lib}
  \end{axis}
\end{tikzpicture}
\caption{Comparison of Launcher timings}\label{fig:launcher_build_times_2}
\end{figure}

\kimnote{I am a bit puzzled about the launcher build times. In Figure 9.1 the Launcher takes very short time, the same is seen in figure 9.5 under "Old slow". In figure 9.5 at the two upper bars the Launcher now takes more the 20 times longer to build then it use to. I think it would be beneficial for you to comment on this drastic development.}


\section{Non-Emulator Testing}\label{sec:non-emulator_testing}
As presented in the previous section, it takes a long time for the Android emulator to start. In addition, the emulator takes memory and CPU time from the actual build process, which is likely to make the build slower. We look at how to test Android applications and libraries sufficiently without using an emulator. Overall, we consider two ways of doing this: Testing on a physical device (connected by USB) and on the Java Virtual Machine (JVM).

\subsection{Testing on a Physical Device}
An alternative to the Android emulator is to run tests on a physical device. A physical device is typically faster than the emulator and it need not to boot every time we build. A downside of testing on a physical device is the expense of having one or more tablets only for testing. If we want to test on a wide range of Android devices, this can be a significant expense for a project without financial income. A single tablet may currently be sufficient for our project though, as we only test on a single emulator configuration anyway.

In the ideal continuous integration setup, each build is tested on all devices we support. Programs such as \emph{Spoon} \parencite{spoon2015}, which automatically distribute a test application to several devices and run it simultaneously, would both reduce build times and improve the overall quality assurance. However, because of the expense of this solution and the limited time left in this sprint, we choose not to look more into this.

\subsection{Testing on the Java Virtual Machine}
One option is to run tests on the Java Virtual Machine instead of the emulated Dalvik Virtual Machine. By not emulating the virtual machine, the test can be executed faster. However, this also means that the tests will not run on the Android operating system but on the operating system running the JVM\@. Because of this, some system features will have to be mocked, which in some cases may not provide a realistic simulation of the Android system. This may be acceptable, though, and we can eventually solve it by running functional test on an emulator at night when timing is no concern.

\subsubsection{Robolectric}
\emph{Robolectric} \parencite{robolectric2015} is a library for testing Android applications without an emulator or device. It contains implementations of the base Android SDK classes such that it can run on the Java Virtual Machine. It supports both unit testing and functional testing by providing access to UI elements and databases. To support this, however, the test case implementation differs slightly from those using the official Android test framework. Because of this, our existing tests need to be rewritten to support the library. In addition, it is not possible to run Robolectric tests on a device or emulator. As a result, it is necessary to have two tests, one using Robolectric and one using the Android test framework, if the test cases should run on both the JVM and an emulator or device.

While Robolectric is likely to speed-up the build times and seems to be relatively easy to use, the changes required to convert existing tests to Robolectric are too extensive for us to perform in this sprint.\todo{Maybe give implementation examples to support statements} Therefore, we choose not to implement Robolectric. However, the library ought to be considered if build times need to be decreased further.
