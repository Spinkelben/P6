\chapter{Improving Build Times}
The project groups want the build times on Jenkins to be faster. When multiple changes are pushed to the master branch within a short space of time, the triggered build jobs will create congestion the build queue. This means that even though the build itself may take only a few minutes, the time it takes from push to finished build may be much longer and exceed the 10 minutes advocated by Kent Beck \parencite{beck2004}.

\begin{chapterorganization}
  \item in \sectionref{sec:measuring_build_times} we measure the time of building the Launcher app;
  \item in \sectionref{sec:dependency_management} we present an alternative solution to the current Git submodule dependency system;
  \item in \sectionref{sec:dependency_repository} we choose a dependency repository for storing binaries;
  \item in \sectionref{sec:dependency_workflow} we define the workflow for the multi-project developers when working with the new dependency system;
  \item in \sectionref{sec:conf_project_to_publish} we configure the Giraf projects to use the new dependency system;
  \item in \sectionref{sec:automating_vm} we describe how versions of binaries are automatically managed;
  \item in \sectionref{sec:faster_build_evaluation} we evaluate the build times after implementing binary dependencies.
\end{chapterorganization}

\section{Measuring Build Times}\label{sec:measuring_build_times}
We measure the build time of the different parts of the Launcher project in order to identify which parts of the build process to make faster. The Launcher project is the main application which depends on many other subprojects (henceforth a ``dependency''). These dependencies are managed as Git submodules \parencite{git-submodules-doc}, which basically clones the contents of a repository (the dependency) at a specific revision into another repository (the dependent project). The build timings are measured on the Jenkins server and shown in \figureref{fig:launcher_build_times_1} (before). This shows the build timings of the Launcher application and the different dependencies (\emph{Oasis-lib}, \emph{Giraf-Component}, \emph{Local-db}, \emph{Barcode-scanner}, and \emph{Metadata}), as well as the start up time of the emulator. As can be seen, the emulator and the \emph{Giraf-component} and \emph{Oasis-lib} projects have the most significant influence on build times. These three parts use about \SI{90}{\percent} of the total build time. The actual Laucher application itself takes only very little part of the total build time.

To understand which parts of the dependencies that take time, we measure the individual build steps (tasks) performed during a build. These can be seen in \appendixref{app:build_times}. The reason that the \emph{Oasis-lib} dependency takes a long time to build is that it contains a great number of tests which run on the emulator. These tests are run every time a project depending on \emph{Oasis-lib} builds --- even though the library itself has not been updated. The most significant task when building the \emph{Giraf-Component} library is the test task as well. However, the \emph{Giraf-Component} library only contains one simple test, so we do not expect the actual test execution time to use much of this time. Instead, we expect it to be caused by the order in which projects are tested. When preparing the tests, the tests from all projects are combined into a single Android application package (APK-file). The first test task run is responsible for installing this application on the emulator, while the subsequent test tasks can skip this step. Because the \emph{Giraf-components} project is the first in the sequence of libraries to be tested, this task also installs the tests on the emulator which is likely to take some time.
\todo{Overvej flere m√•linger og tag gennemsnit}
\begin{figure}
\centering
\tikzsetnextfilename{timings_beforeemulatorupdate}
\begin{tikzpicture}[]
  \begin{axis}[
    xbar stacked,
    %scale only axis,
    width=\textwidth,
    axis y line*= none, axis x line*= bottom,
    %xmajorgrids = true,
    ytick = data,
    yticklabels = {Before, After},
    tick align = outside,
    %xtick pos = left,
    bar width=6mm,
    y=8mm,
    enlarge y limits={abs=0.625},
    %nodes near coords,
    legend style={
      at={(0.5,-0.35)},
      legend columns=4,
      anchor=north,
      yshift=0ex,
      xshift=0ex,
      draw=none
      %legend cell align=left
    },
    area legend,
    xlabel = {Time (seconds)},
    xmin = 0
  ]
    \addplot[colorGshade, fill=colorG] coordinates
    {(0.2,0) (0.209,1)};
    \addlegendentry{Metadata}
    \addplot[colorFshade, fill=colorF] coordinates
    {(6.625,0) (6.625,1)};
    \addlegendentry{Barcode-scanner}
    \addplot[colorEshade, fill=colorE] coordinates
    {(8.393,0) (8.393,1)};
    \addlegendentry{Launcher}
    \addplot[colorDshade, fill=colorD] coordinates
    {(17.223,0) (17.223,1)};
    \addlegendentry{Local-db}
    \addplot[colorCshade, fill=colorC] coordinates
    {(160.000,0) (18.000,1)};
    \addlegendentry{Emulator}
    \addplot[colorBshade, fill=colorB] coordinates
    {(104.696,0) (104.696,1)};
    \addlegendentry{Giraf-component}
    \addplot[colorAshade, fill=colorA] coordinates
    {(159.497,0) (159.497,1)};
    \addlegendentry{Oasis-lib}
  \end{axis}
\end{tikzpicture}
\caption{Timings during build of the Launcher project before and after updating emulator plugin}\label{fig:launcher_build_times_1}
\end{figure}

As a preparation step, we first update the Android Emulator Jenkins plugin to a new version with improved emulator stability. We do this to ensure that we do not work on improving parts which are already improved in the most recent version of the plugin. After updating, we measure the build times again. As shown in \figureref{fig:launcher_build_times_1} (after), the emulator startup time is significantly decreased. Because of this, the emulator startup time is no longer the primary concern, and we focus on decreasing the dependency build times.

One obvious way of decreasing overall build times is to use faster hardware on the server. However, because the multi-project has no financial income, buying new hardware is generally the last resort. In addition, it is difficult to estimate exactly how much of a decrease this will give in practice. Another option is to not test dependencies when dependent projects are build, but only when changes happen in the actual dependency project. While this will decrease the overall build times, each dependency is still built every time a dependent project is built, which limits the amount by which we can decrease the total build times. There may as well arise some quality assurance issues by not testing each build of the dependency. Because of this, we look at improving the build times in a different way, specifically by using pre-compiled libraries.

\section{Dependency Management}\label{sec:dependency_management}
Instead of building and testing dependencies each time a dependent project is built, we look at referencing pre-compiled and pre-tested library files. We are inspired by the way \mono{.jar}-files are typically used as libraries for Java projects. This way of managing libraries has a number of advantages compared to the current setup:
\begin{description}
  \item [Pre-Compiled and Pre-Tested] Libraries are binary pre-compiled and pre-tested files. This means that dependent projects do not have to build and test all dependencies, which decreases the build time significantly.
  \item[Quality Control] Libraries are built and released only if the tests pass, so there will never be dependencies which cannot compile or do not work\footnote{Of course, there may be bugs even if all tests pass, but good test cases decrease the risk}.
  \item[Integrity] All libraries are built on the same machine and build environment, which means that no machine-specific configurations will influence the released libraries \parencite{humble2010, huttermann2014}.
  \item[Cleaner Structure] Nested dependencies (dependency A depends on dependency B which depends on dependency C) is well defined and nicely handled. The individual libraries do not include their dependencies, so it is always the dependent library that has to include all dependencies. Currently, the same dependency may be included multiple times in the same project.
\end{description}
The Android counterpart of Java \mono{.jar}-files is \mono{.aar}-files. These files are similar to \mono{.jar}-files, except that they can contain Android-specific dependencies such as icon resources as well \parencite{android-aar}.

With this solution, it is clear that we no longer want to use submodules for managing dependencies. Coincidentally, the Git-responsible group in the multi-project work on a user story which states \us{Remove Git submodules}. The reason for this user story is that the developers generally find the submodules difficult to work with. Because this overlap with our solution to making build times faster, we decide to solve this in collaboration.

An important requirement for the solution, besides removing Git submodules and improving build times, is that every build should be reproducible. This means that we must be able to reproduce any previously released version. This is a very important part of continuous integration as it makes it possible to reproduce bugs from previous versions \parencite{fowlerReproducibleBuild,humble2010}. In the current way of managing dependencies, this requirement is fulfilled.

\subsection{Agreement Upon Submodule Replacement Strategy}
The Git-responsible group initially propose to remove submodules by merging all repositories into one, each project having its own directory located in the root directory of the repository, as shown in \figureref{fig:single_repo_structure}. Dependencies are then handled by referring to the relative path of the dependency. For example, if \mono{ProjectA} depends on \mono{ProjectB}, \mono{ProjectA} will contain a reference to \mono{../ProjectB}. This solution makes all releases reproducible, which is one of the requirements to the solution. The repository can simply be checked out to a specific commit corresponding to a specific release.
\begin{figure}
  \dirtree{%
.1 /.
.2 ProjectA.
.3 \ldots.
.2 ProjectB.
.3 \ldots.
.2 ProjectC.
.3 \ldots.
.2 ProjectD.
.3 \ldots.
}
\caption{Single repository file structure} \label{fig:single_repo_structure}
\end{figure}
A problem with this, however, is that the structure does not use pre-compiled libraries and as such it does not decrease build times as much as we want. Each dependency is built every time the dependent project is built.

An additional problem is that all projects are forced to use the most recent versions of its dependencies. As soon as a dependency is updated, it is automatically applied in all dependent projects. If the interface to a library changes without keeping backward compatibility, all dependent projects will stop working.

Instead, we need a structure which allows projects to reference their dependencies as pre-built libraries while being able to reproduce any build in history. For inspiration, we look at how dependency management is done in the five most starred Android projects on Github\footnote{As of April \nth{15}, these are \emph{ioshed}, \emph{ViewPagerIndicator}, \emph{retrofit}, \emph{EventBus}, and \emph{PhotoView}.}. In all of these projects, dependencies are handled by Gradle and Maven. Maven is a build tool similar to Gradle, but its dependencies management mechanisms are supported in many build tools, including Gradle. Dependencies are declared in the build configuration file, for example in a Gradle file, each of which uniquely identified with a group (package), name, and version number. \listingref{lst:dependency_declaration} shows how a dependency (the \emph{gson} library) is declared in a Gradle file. When the project is built, the build system automatically searches for the dependencies on the declared repositories and downloads them. Because the version code (\mono{2.0} in this case) is used to identify dependencies, and the build file is under version control, it is possible reproduce builds.

\begin{gradlecode}[caption={Dependency declaration in Gradle},label={lst:dependency_declaration}]
repositories {
  mavenCentral()
}
dependencies {
  compile 'com.google.code.gson:gson:2.0'
}
\end{gradlecode}

\section{Dependency Repository}\label{sec:dependency_repository}
By hosting our own internal Maven artifact repository for our libraries, we are able to declare the dependencies in the build-file and at the same time remove Git submodules and make builds happen faster. This means that we use a separate repositories for source code and binary files. The main reason for this is that Git does not handle binary files well. It keeps every version of binary files \parencite{gitwebsite_attributes}, which will use much space over time. In an artifact repository, on the other hand, only release versions of libraries and a configurable number of development (pre-release) versions are saved.

Different pieces of software for managing artifact repositories exist, which we will present in this section. We restrict ourselves to looking at free repository systems supported by Gradle \parencite{gradle-dependencies-doc}: \emph{Apache Archiva} \parencite{archiva-website}, \emph{Sonatype Nexus} \parencite{nexus-website}, and \emph{Artifactory} \parencite{artifactory-website}. Overall, the only requirements for an artifact repository management system are:
\begin{description}
  \item[Repository Browser] It should be possible to browse the artifacts in the repositories, so that the developers can identify the most recent versions of the libraries.
  \item[Role Management] Every developer should be able to browse the repository, but only specific people should be able to configure the repositories.
\end{description}
Each of the three repository systems comply with these requirements. They can all be browsed and configured through a web server. As such, it does not really matter which system we choose. We choose to use Artifactory because it has a plugin for Jenkins which may be useful for future projects. We install the software on our server and do the actual submodule replacement in collaboration with the Git responsible group.

\section{Dependency Workflow}\label{sec:dependency_workflow}
Because of the new way of managing dependencies, all developers have to change their workflows. To make the transition run smooth, we define a workflow for the new structure, which defines the following tasks:
\begin{description}
  \item[Release Management and Versioning] During development, libraries should be released as work-in-progress artifacts. When they are stable, new versions should be released.
  \item[Declaring Dependencies] It should be clear for the developers how to declare dependencies and their versions.
  \item[Local Development] Developers should be able to test changes to libraries in dependent projects without committing them to the master branch.
\end{description}

To learn the developers how to use the new dependency management, we demonstrate the workflow we present here during the multi project meeting. We also write a guide which they can use for future reference.\todo{Add to appendix?}

\subsection{Release Management and Versioning}
With the introduction of artifacts, we now distinguish release versions from pre-release versions. In addition, a release can be a \emph{major}, \emph{minor}, or \emph{patch} release. The developers need some guidelines to know when to release the different kind of releases. Rather than inventing our own convention, we rely on the Semantic Versioning 2.0.0 specification \parencite{semver2015}, which has been adopted in several Apache projects \parencite{apacheapr,apacheisis,apacheaccumulo}. Because the versioning is clearly specified, we expect to avoid potential problems caused by libraries breaking backward compatibility. In summary, the Semantic Versioning 2.0.0 specification states that the version name is of the form \mono{major.minor.patch}, each of which being a non-negative integer. For example, version \mono{2.5.1} has major version 2, minor version 5, and patch version 1. The individual numbers are increased as new versions are released. To summarize the Semantic Versioning 2.0.0 specification, the numbers are increased according to the following:
\begin{description}
  \item[Major] When changes without backward compatibility are introduced, it should be released as a new major version. The minor and patch numbers are reset to 0.
  \item[Minor] Minor releases are used when new functionality is added with backward compatibility. The major version is unchanged and the patch version is reset to 0.
  \item[Patch] A patch is for introducing changes without new functionality (typically bug fixes). The major and minor versions are left unchanged.
\end{description}

During development, pre-release versions can be denoted by the version code followed by a hyphen and an identifier (e.g.\ \mono{2.5.1-ALPHA} or \mono{2.5.1-SNAPSHOT}). Due to the specifics of Maven dependencies, we require this identifier to always be \mono{SNAPSHOT}. This enables Maven to handle pre-releases differently than release versions.

\subsection{Declaring Dependencies}
The new pre-built dependencies are declared almost the same way as previously. Instead of referring a path to a local directory containing the dependency, the reference is declared as a Maven dependency (as previously described). To accommodate this, we release the current version of each library as version 1.0.0 and make all dependent projects reference these. \listingref{lst:dependency_declaration_giraf} shows an example of how the dependencies are declared for a Giraf-project, including the declaration of the repository containing the dependencies.

\begin{gradlecode}[caption={Dependency declaration for a Giraf project},label={lst:dependency_declaration_giraf}]
repositories {
    maven {
        url 'http://cs-cust06-int.cs.aau.dk/artifactory/libraries'
    }
    mavenLocal()
}

dependencies {
    compile(group: 'dk.aau.cs.giraf', name: 'girafComponent', version: '1.3.0-SNAPSHOT', ext: 'aar')
    compile(group: 'dk.aau.cs.giraf', name: 'oasisLib', version: '1.1.2', ext: 'aar')
}
\end{gradlecode}

\subsection{Local Development}
Developers must be able to test their changes in the dependent projects locally without committing their changes, as part of continuous integration \parencite{fowlerCI}. Our solution is to publish the dependency on a local Maven repository on every development machine. To test the dependency in another project, the dependent project points to the local repository rather than that on the common repository. Conveniently, the Maven plugin for Gradle has support for publishing and referring to local repositories. The build task \mono{publishToMavenLocal} publishes an artifact to the local repository.

\todo{Eventually show diagram}
% DIAGRAM:  http://stackoverflow.com/questions/11891890/should-artifactory-not-be-used-to-capture-the-build-artifacts-that-jenkins-produ

\section{Configuring the Projects to Publish}\label{sec:conf_project_to_publish}
\todo{Ligger jeg rigtigt?}
Each library project has to be configured to publish, locally and to Artifactory. This configuration is done in the build files. Instead of having to repeat the same information in the build file for every library project, we make a Gradle plugin which defines all properties needed for publishing, called the \mono{giraf-lib-gradle-plugin}. The plugin contains the URL to the snapshot and release repositories, the path to a credentials file (to Artifactory), and configurations for local publishing. It also declares a rename task, which renames the output file, such that Jenkins knows its name when it is to upload it. At last, it makes the \mono{publishToMavenLocal} task dependent on the \mono{build} task, as it would be a hassle to manually make sure to build first. With this plugin we only have to apply it in the build files to make them publish to Artifactory.\todo{Tilf√∏j kode til appendiks?}

Because the credentals file is stored on the build server, it is also not possible for the developers to publish libraries themselves; each build must pass on Jenkins before it is released.

\section{Automating Dependency Management}\label{sec:automating_vm}
With the dependency workflow defined, we integrate it with continuous integration. As earlier mentioned, we want to automate as much as possible to ease the work of the developers. For dependency management, Gradle already does a lot for us: It automatically locates and downloads declared dependencies and creates tasks for publishing new ones to the artifact repository.

In addition to this, we automate release versioning to some degree. Developers need not to declare the version of a library in its build file --- instead, they simply include the keywords \mono{@patch}, \mono{@minor}, or \mono{@major} in the commit message to release a patch, minor, or major version, respectively. This automatically takes care of increasing and resetting version numbers. For example, if the current version is \mono{1.2.1}, a \mono{@minor} keyword will release a new artifact with version \mono{1.3.0}. If no keyword is given, the release is assumed to be a pre-release, which causes the version name to be the \emph{next} patch release number with a \mono{-SNAPSHOT} postfix (e.g.\ \mono{1.2.2-SNAPSHOT} if the most recent release is \mono{1.2.1}). If multiple commits are pushed at the same time, we trigger only one pre-release build per release. For example, if it contains four commits with messages \mono{test1}, \mono{test2}, \mono{@patch}, \mono{test3}, respectively, two pre-releases (one before and one after the patch) and one patch are build. Similarly, if a push contains several commits without any release keyword, only one pre-release will be built. \todo{Maybe this could be illustrated somehow?}
\begin{figure}
    \centering
    \begin{tikzpicture}[
    simple/.style={draw, circle, minimum size=0.5cm}]

    %Commit nodes
    \node[simple] (master-1) at (0,5) {A};
    \node[simple] (local-1) at (2,4) {B};
    \node[simple] (local-2) at (2,3) {C};
    \node[simple] (local-3) at (2,2) {D};
    \node[simple] (local-4) at (2,1) {E};
    \node[simple] (master-2) at (0,0) {F};

    %Titles
    \node(master) [above=of master-1, minimum size=0.5cm, yshift=-1cm] {\mono{master}};
    %\path \let \p1 = (1,1), \p2 = (2,2) in node at (1, 1) {\mono{local}};
    %\node(local) [right=of master] {\mono{Local}};
    %\node(version-title) [right=of local] {\mono{Version}};
    %\node(commit-title) [right=of version-title] {\mono{Commit message}};

    %Versions
    \node(major-version) [right=of local-3] {\mono{1.2.4}};
    \node(init-version) [right=of master-1, xshift=2cm] {\mono{1.2.3}};
    \node(old-snap)  [right=of local-2] {\mono{1.2.4-SNAPSHOT}};
    \node(new-snap)  [right=of local-4] {\mono{1.2.5-SNAPSHOT}};

    %Patch node
    \node(patch-note) [right=of major-version] {\mono{@patch}};

    \end{tikzpicture}
\end{figure}
The Git hook previously described is extended with functionality to manage this. We implement this automation in collaboration with the Git-responsible group. As part of the implementation phase, we refactor by changing the programming language from Bash to Python, because of the greater level of abstraction provided by Python compared to Bash. Part of the code is shown in \listingref{lst:git_hook_trigger_build}. This function is called for each commit message contained in the push. It first identifies the library corresponding to the repository pushed to (lines 13--14), and afterwards checks for keywords in the git message and formats the new version name (lines 18--33). Jenkins is then triggered with a HTTP POST request containing the Jenkins job name, the version name of the release, and the commit id of the release commit as arguments. Finally, the library versions are updated in a global library object and the version name is printed to the user. The full code can be seen in \appendixref{app:git_hook}. The most recent versions of the different libraries are stored in a file together with the names of their repositories and Jenkins jobs.

\begin{pythoncode}[caption=Part of the git hook responsible for setting library version names and triggering Jenkins,label=lst:git_hook_trigger_build]
def trigger_build(commit_msg, commit_id, libraries, repo_name, publish_snapshot=False):
    """
    Triggers a build on Jenkins.

    Parameters:
        commit_msg:       The contents of the commit message. Used for versioning.
        commit_id:        The id of the commit to build.
        libraries:        The known libraries and their versions.
        repo_name:        The name of the repository.
        publish_snapshot: If true, snapshots will be published.
    """
    version_name = ""
    for lib in libraries:
        if lib.name == repo_name and commit_msg != None:
            new_major = lib.major
            new_minor = lib.minor
            new_patch = lib.patch
            if "@major" in commit_msg.lower():
                new_major = str(int(lib.major) + 1)
                new_minor = "0"
                new_patch = "1"
                version_name = "%s.0.0" % (new_major,)
            elif "@minor" in commit_msg.lower():
                new_minor = str(int(lib.minor) + 1)
                version_name = "%s.%s.0" % (lib.major, new_minor)
                new_patch = "1"
            elif "@patch" in commit_msg.lower():
                version_name = "%s.%s.%s" % (lib.major, lib.minor, lib.patch)
                new_patch = str(int(lib.patch) + 1)
            else:
                if not publish_snapshot:
                    return
                version_name = "%s.%s.%s-SNAPSHOT" % (lib.major, lib.minor, lib.patch)
            # Send request
            try:
                send_build_request(lib.jobname, version_name, commit_id)
                # Apply lib changes (request succeeded)
                lib.major = new_major
                lib.minor = new_minor
                lib.patch = new_patch
                print_version_name(version_name)
            except (ConnectionError, Timeout) as e:
                print "ERROR TRIGGERING BUILD"
                print e
            return
\end{pythoncode}

\section{Evaluation of Build Times with Binary Dependencies}\label{sec:faster_build_evaluation}

\begin{figure}
\centering
\tikzsetnextfilename{timings_beforeemulatorupdate}
\begin{tikzpicture}[]
  \begin{axis}[
    xbar stacked,
    %scale only axis,
    width=\textwidth,
    axis y line*= none, axis x line*= bottom,
    %xmajorgrids = true,
    ytick = data,
    yticklabels = {Before, After},
    tick align = outside,
    %xtick pos = left,
    bar width=6mm,
    y=8mm,
    enlarge y limits={abs=0.625},
    %nodes near coords,
    legend style={
      at={(0.5,-0.35)},
      legend columns=4,
      anchor=north,
      yshift=0ex,
      xshift=0ex,
      draw=none
      %legend cell align=left
    },
    area legend,
    xlabel = {Time (seconds)},
    xmin = 0
  ]
    \addplot[colorGshade, fill=colorG] coordinates
    {(0.2,0) (0.209,1)};
    \addlegendentry{Metadata}
    \addplot[colorFshade, fill=colorF] coordinates
    {(6.625,0) (6.625,1)};
    \addlegendentry{Barcode-scanner}
    \addplot[colorEshade, fill=colorE] coordinates
    {(8.393,0) (8.393,1)};
    \addlegendentry{Launcher}
    \addplot[colorDshade, fill=colorD] coordinates
    {(17.223,0) (17.223,1)};
    \addlegendentry{Local-db}
    \addplot[colorCshade, fill=colorC] coordinates
    {(160.000,0) (18.000,1)};
    \addlegendentry{Emulator}
    \addplot[colorBshade, fill=colorB] coordinates
    {(104.696,0) (104.696,1)};
    \addlegendentry{Giraf-component}
    \addplot[colorAshade, fill=colorA] coordinates
    {(159.497,0) (159.497,1)};
    \addlegendentry{Oasis-lib}
  \end{axis}
\end{tikzpicture}
\caption{Comparison of Launcher timings}\label{fig:launcher_build_times_2}
\end{figure}

\subsection{Android Emulator Bug}
When we started to work on improving build times, a new version of the Android Emulator Plugin (2.13) was released. This release contains a change in the way emulator startup is detected. It is necessary to detect when the Android emulator has started, so that APKs can be installed on it and tests can be run. Previously the plugin had checked whether the emulator has started up using \mono{adb shell getprop dev.bootcomplete}. However, this property does not specify that the emulator has started fully, as it may still be in the boot animation when this property returns true. As such the check was switched to  \mono{adb shell getprop init.svc.bootanim} which indicates that the emulator is no longer in the boot animation, and thus have started fully. However, since the emulator in the plugin has the \mono{-no-boot-anim} flag, the emulator has no boot animation. This is to improve loading times, but it also means that the new check for the boot animation will return true immediately, as there is no boot animation. This results in the plugin specifying that the emulator is ready too early, which can lead to potential errors when working with the emulator.

At first this change did not affect us, since building times when building submodules were sufficiently long for the emulator to have started fully regardless. However, as we improve building times with binary dependencies, we start getting no test found errors because of the not yet started emulator. We submit a bug report for the plugin\footnote{\url{https://issues.jenkins-ci.org/browse/JENKINS-27702}} and a pull request removing the \mono{-no-boot-anim} flag for the compiler\footnote{\url{https://github.com/jenkinsci/android-emulator-plugin/pull/49}}. Removing the \mono{-no-boot-anim} flag will result in slightly longer loading times for the emulator, but is necessary to detect that the emulator has started fully.

\section{Non-Emulator Testing}
As presented in the previous section, it takes a long time for the Android emulator to start. In addition, the emulator takes memory and CPU-time from the actual build process, which is likely to make the build slower. We look at how to test Android applications and libraries sufficiently without using an emulator. Overall, we consider two ways of doing this: Testing on the Java Virtual Machine (JVM) and on a physical device (connected by USB).

\subsection{Testing on the Java Virtual Machine}
One option is to run tests on the Java Virtual Machine instead of the emulated Dalvik Virtual Machine. By not emulating the virtual machine, the test can be executed faster. However, this also means that the tests will not run on the Android operating system but on the operating system running the JVM\@. Because of this, some system features will have to be mocked, which in some cases may not provide a realistic simulation of the Android system. This may be acceptable, though, and we can eventually solve it by running functional test on an emulator at night when timing is no concern.

\subsubsection{Robolectric}
\emph{Robolectric}\parencite{robolectric2015} is a library for testing Android applications without an emulator or device. It contains implementations of the base Android SDK classes such that it can run on the Java Virtual Machine. It supports both unit testing and functional testing by providing access to UI elements and databases. To support this, however, the test case implementation differs slightly from those using the official Android test framework. Because of this, our existing tests need to be rewritten to support the library. In addition, it is not possible to run Robolectric tests on a device or emulator. As a result, it is necessary to have two tests, one using Robolectric and one using the Android test framework, if the test cases should run on both the JVM and an emulator or device.

While Robolectric is likely to speed-up the build times and seems to be relatively easy to use, the changes required convert existing tests to Robolectric are too extensive for us to perform in this sprint.\todo{Maybe give implementation examples to support statements} Therefor, we choose not to implement Robolectric. However, the library ought to be considered if build times need to be decreased further.

\subsection{Testing on a Physical Device}

% http://square.github.io/spoon/
